{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample PySpark Notebook\n",
    "\n",
    "See the README for more details a link to the home repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete Uniform across 0-999999\n",
      "  Sampling at 15.250% (with replacement)\n",
      "  Analytic     mean(stdev): 499999.500(288675.135)\n",
      "  Experimental mean(stdev): 500801.263(288604.931)\n"
     ]
    }
   ],
   "source": [
    "# do something to prove it works\n",
    "\n",
    "# For the DISCRETE uniform distributuion on range a-b,\n",
    "# Mean = (a+b)/2, Variance = ((b - a + 1)**2 - 1) / 12\n",
    "\n",
    "def discrete_uniform_experiment():\n",
    "    from math import sqrt\n",
    "    NUM = 1000000\n",
    "    SAMPLE = 0.1525\n",
    "    a, b = 0, NUM-1\n",
    "    mean = (a+b)/2\n",
    "    var = ((b - a + 1)**2 - 1) / 12\n",
    "    stdev = sqrt(var)\n",
    "    print(\"Discrete Uniform across %d-%d\" % (a,b))\n",
    "    print(\"  Sampling at %.3f%% (with replacement)\" % (SAMPLE * 100,))\n",
    "    print(\"  Analytic     mean(stdev): %.3f(%.3f)\" % (mean,stdev))\n",
    "\n",
    "    # We find an experiment mean and stdev by taking a sample from the\n",
    "    # entire distribution WITH REPLACEMENT. Note that we use cache()\n",
    "    # to execute multiple computations across the cluster.\n",
    "    rdd = sc.parallelize(range(NUM)).sample(True, SAMPLE).cache()\n",
    "    exp_count = rdd.count()\n",
    "    exp_mean = rdd.sum() / exp_count\n",
    "    exp_devs = rdd.map(lambda x: (x - exp_mean) ** 2)\n",
    "    exp_stdev = sqrt(exp_devs.sum() / (exp_count - 1))\n",
    "    print(\"  Experimental mean(stdev): %.3f(%.3f)\" % (exp_mean, exp_stdev))\n",
    "\n",
    "discrete_uniform_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 4), (1, 4), (2, 2)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick example of word counts by line\n",
    "\n",
    "# lines = sc.textFile(\"file:///tmp/sampleFile.txt\")\n",
    "lines = sc.parallelize([\n",
    "    \"This is line one\",\n",
    "    \"This is line two\",\n",
    "    \"Last line.\"\n",
    "])\n",
    "\n",
    "def words(line_index):\n",
    "    line, index = line_index\n",
    "    return (index, line.split(\" \"))\n",
    "\n",
    "lines.zipWithIndex().map(words).map(\n",
    "    lambda kv: (kv[0], len(kv[1]))\n",
    ").reduceByKey(\n",
    "    lambda x,y: x+y\n",
    ").collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
